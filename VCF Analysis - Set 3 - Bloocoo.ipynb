{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VCF Locations   Folder     File\n",
    "condition1VCF  = \"vcf/%s\" % \"synthetic.challenge.set3.bloocoo.default.nobqsr.raw.snps.indels.vcf\"\n",
    "condition2VCF  = \"vcf/%s\" % \"synthetic.challenge.set3.bloocoo.default.bqsr.raw.snps.indels.vcf\"\n",
    "truthVCF       = \"vcf/truth-set/%s\" % \"synthetic.challenge.set3.tumor.20pctmasked.truth.vcf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show Plots Inline\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "from statistics import mean, median, mode, stdev, variance\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "import operator\n",
    "\n",
    "# Import General Libs\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as Plot\n",
    "import numpy as Np\n",
    "import vcf as VCF\n",
    "\n",
    "Plot.ion()\n",
    "\n",
    "# Set matplotlib style\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "#\n",
    "# Data Structuring\n",
    "#\n",
    "\n",
    "# Variant Hashing Function\n",
    "def hashVariants (records, props, algorithm = \"md5\"):\n",
    "    \"\"\"\n",
    "    \n",
    "    Hash VCF Records and Check for Collisions.\n",
    "    Accepts Reader object (records) and an algorithm string (algorithm).\n",
    "    \n",
    "    @Params:\n",
    "        PARAMETER    USAGE      DEFAULT   DESCRIPTION\n",
    "        records    - Required -         - Iterable records object\n",
    "        props      - Required -         - Properties of record in records iterable\n",
    "        algorithm  - Optional - \"md5\"   - String of hashing algorithm \n",
    "    @Returns\n",
    "        hashMap    - OrderdDict\n",
    "        collisions - Boolean\n",
    "        \n",
    "    \"\"\"\n",
    "    import hashlib\n",
    "    from collections import OrderedDict\n",
    "    hashMap, count, collisions = OrderedDict(), 0, False\n",
    "    for record in records:\n",
    "        variantStr = \"\".join([str(getattr(record, prop)) for prop in props])\n",
    "        variantMD5 = getattr(hashlib, algorithm)(variantStr.encode()).hexdigest()\n",
    "        hashMap[variantMD5] = record\n",
    "        count += 1\n",
    "    if len(hashMap.keys()) != count:\n",
    "        collisions = True\n",
    "        print(\"Warning: Collision occurred. Try using a difference hashing function.\")\n",
    "        print(\"Available algorithms: %s\\n\" % \", \".join(hashlib.algorithms_available))\n",
    "    return hashMap, collisions\n",
    "\n",
    "def generateAnalysis (conditionHashMap, truthHashMap, metricKey = \"TLOD\", operation = \"<\", threshold = 100):\n",
    "    # Map Operators\n",
    "    operators = {\n",
    "        '>': operator.gt,\n",
    "        '<': operator.lt,\n",
    "        '>=': operator.ge,\n",
    "        '<=': operator.le,\n",
    "        '=': operator.eq\n",
    "    }\n",
    "    # Setup Analysis by Threshold\n",
    "    analysis = {\n",
    "        \"tp\"          : set(),\n",
    "        \"fp\"          : set(),\n",
    "        \"tn\"          : set(),\n",
    "        \"fn\"          : set(),\n",
    "        \"sensitivity\" : 0.0,\n",
    "        \"specificity\" : 0.0,\n",
    "        \"precision\"   : 0.0,\n",
    "        \"recall\"      : 0.0,\n",
    "        \"tpr\"         : 0.0,\n",
    "        \"tnr\"         : 0.0,\n",
    "        \"fpr\"         : 0.0,\n",
    "        \"fnr\"         : 0.0,\n",
    "        \"accuracy\"    : 0.0,\n",
    "        \"f1score\"     : 0.0,\n",
    "        \"fdr\"         : 0.0,\n",
    "        \"for\"         : 0.0,\n",
    "        \"ppv\"         : 0.0,\n",
    "        \"npv\"         : 0.0,\n",
    "        \"diagnosticOR\": 0.0,\n",
    "        \"n\"           : 0\n",
    "    }\n",
    "    # Sort Variants into TP/TN/FP/FN Sets\n",
    "    for hashKey, record in conditionHashMap.items():\n",
    "        if operators[operation](float(record.INFO[metricKey]), threshold):\n",
    "            if hashKey in truthHashMap:\n",
    "                analysis[\"fn\"].add(hashKey)\n",
    "            else:\n",
    "                analysis[\"tn\"].add(hashKey)\n",
    "        else:\n",
    "            if hashKey in truthHashMap:\n",
    "                analysis[\"tp\"].add(hashKey)\n",
    "            else:\n",
    "                analysis[\"fp\"].add(hashKey)\n",
    "\n",
    "    # TP/TN/FP/FN Values - Add 0.000000000001 to Each to Prevent Zero-Division\n",
    "    # While the Addition Theoretically Introduces a Bias, Practically Statistics are Unchanged (Validated)\n",
    "    tp = len(analysis[\"tp\"]) + 0.000000000001\n",
    "    tn = len(analysis[\"tn\"]) + 0.000000000001\n",
    "    fp = len(analysis[\"fp\"]) + 0.000000000001\n",
    "    fn = len(analysis[\"fn\"]) + 0.000000000001\n",
    "\n",
    "    # Statistics (Some Computations Replicated for Naming)\n",
    "    analysis[\"sensitivity\"]   = tp / (tp + fn)\n",
    "    analysis[\"specificity\"]   = tn / (fp + tn)\n",
    "    analysis[\"precision\"]     = tp / (tp + fp)\n",
    "    analysis[\"recall\"]        = tp / (tp + fn)\n",
    "    analysis[\"tpr\"]           = tp / (tp + fn)\n",
    "    analysis[\"tnr\"]           = tn / (fp + tn)\n",
    "    analysis[\"fpr\"]           = fp / (fp + tn)\n",
    "    analysis[\"fnr\"]           = fn / (fn + tp)\n",
    "    analysis[\"accuracy\"]      = (tp + tn) / (tp + tn + fp + fn)\n",
    "    analysis[\"f1score\"]       = (2 * tp) / ((2 * tp) + (fp + fn))\n",
    "    analysis[\"fdr\"]           = fp / (fp + tp)\n",
    "    analysis[\"for\"]           = fn / (fn + tn)\n",
    "    analysis[\"ppv\"]           = tp / (fp + tp)\n",
    "    analysis[\"npv\"]           = tn / (fn + tn)\n",
    "    analysis[\"diagnosticOR\"]  = (tp / fp) / (fn / tn)\n",
    "    analysis[\"n\"]             = tp + fp + tn + fn\n",
    "    return analysis\n",
    "\n",
    "# Compute Lots of Statistics n' Stuff\n",
    "def generateAnalyses (conditionHashMap, truthHashMap, metricKey = \"TLOD\", thresholds = 100, skip = 1):\n",
    "    # Setup Data Structures\n",
    "    analyses   = OrderedDict()\n",
    "    # Use Thresholds to Classify Positive or Negative \n",
    "    for threshold in range(0, thresholds, skip):\n",
    "        analyses[threshold] = generateAnalysis(conditionHashMap, truthHashMap, metricKey = metricKey, threshold = threshold)\n",
    "    return analyses\n",
    "\n",
    "def subsetHashMapByKeys (hashMap, keys, isfound = True):\n",
    "    subset = {}\n",
    "    for md5, record in hashMap.items():\n",
    "        if isfound:\n",
    "            if md5 in keys:\n",
    "                subset[md5] = record\n",
    "        else:\n",
    "            if md5 not in keys:\n",
    "                subset[md5] = record\n",
    "    return subset\n",
    "\n",
    "# Get Info Data From Records in Records HashMap\n",
    "def subsetHashMapByInfoThreshold (hashMap, threshold, operation = \">\", key = \"TLOD\"):\n",
    "    subset, excluded = {}, {}\n",
    "    operators = {\n",
    "        '>': operator.gt,\n",
    "        '<': operator.lt,\n",
    "        '>=': operator.ge,\n",
    "        '<=': operator.le,\n",
    "        '=': operator.eq\n",
    "    }\n",
    "    for md5, record in hashMap.items():\n",
    "        if key in record.INFO.keys() and operators[operation](record.INFO[key], threshold):\n",
    "            subset[md5] = record\n",
    "        else:\n",
    "            excluded[md5] = record\n",
    "    return subset, excluded\n",
    "\n",
    "# Get Format Data From Records in Records HashMap\n",
    "def subsetHashMapByFormatThreshold (hashMap, threshold, operation = \">\", key = \"AF\", sampleIdx = 0):\n",
    "    subset, excluded = {}, {}\n",
    "    operators = {\n",
    "        '>': operator.gt,\n",
    "        '<': operator.lt,\n",
    "        '>=': operator.ge,\n",
    "        '<=': operator.le,\n",
    "        '=': operator.eq\n",
    "    }\n",
    "    for md5, record in hashMap.items():\n",
    "        sample = record.samples[sampleIdx]\n",
    "        try:\n",
    "            if type(sample[key]) is list and sum(operators[operation](sample[key], threshold)):\n",
    "                subset[md5] = record\n",
    "            elif operators[operation](sample[key], threshold):\n",
    "                subset[md5] = record\n",
    "            else: \n",
    "                excluded[md5] = record\n",
    "        except:\n",
    "            excluded[md5] = record\n",
    "    return subset, excluded\n",
    "\n",
    "# Get Info Data From Records in Records HashMap\n",
    "def subsetHashMapByInfoRange (hashMap, rangeTup, key = \"TLOD\"):\n",
    "    subset, excluded = {}, {}\n",
    "    for md5, record in hashMap.items():\n",
    "        if key in record.INFO.keys() and record.INFO[key] > rangeTup[0] and record.INFO[key] <= rangeTup[1]:\n",
    "            subset[md5] = record\n",
    "        else:\n",
    "            excluded[md5] = record\n",
    "    return subset, excluded\n",
    "\n",
    "# Get Format Data From Records in Records HashMap\n",
    "def subsetHashMapByFormatRange (hashMap, rangeTup, key = \"AF\", sampleIdx = 0):\n",
    "    subset, excluded = {}, {}\n",
    "    for md5, record in hashMap.items():\n",
    "        sample = record.samples[sampleIdx]\n",
    "        if sample[key]:\n",
    "            if type(sample[key]) is list:\n",
    "                add = sum(sample[key])\n",
    "                if rangeTup[0] == 0:\n",
    "                    subset[md5] = record\n",
    "                elif add > rangeTup[0] and add <= rangeTup[1]:\n",
    "                    subset[md5] = record\n",
    "            else:\n",
    "                if sample[key] > rangeTup[0] and sample[key] <= rangeTup[1]:\n",
    "                    subset[md5] = record\n",
    "        else:\n",
    "            excluded[md5] = record\n",
    "    return subset, excluded\n",
    "\n",
    "# Generate Analysis by Threshold - A Macro Really\n",
    "def generateMultipleAnalyses (condition, truth, key, thresholds, byType = \"info\"):\n",
    "    analyses = []\n",
    "    i = 0\n",
    "    printProgress(i, len(thresholds), prefix = \"Generating Analyses\", suffix = \"Computed\", barLength = 50)\n",
    "    for threshold in thresholds:\n",
    "        if byType.lower() == \"info\":\n",
    "            subset = subsetHashMapByInfo(condition, threshold, key = key)\n",
    "        if byType.lower() == \"format\":\n",
    "            subset = subsetHashMapByFormat(condition, threshold, key = key)\n",
    "        if subset:\n",
    "            analyses.append(generateAnalyses(subset, truth))\n",
    "            i += 1\n",
    "            printProgress(i, len(thresholds), prefix = \"Generating Analyses\", suffix = \"Computed\", barLength = 50)\n",
    "        else:\n",
    "            print(\"Error Subsetting: Ensure byType is specified as either 'info' or 'format' and that the key exists.\")\n",
    "    return analyses\n",
    "\n",
    "#\n",
    "# VCF Parsing\n",
    "#\n",
    "\n",
    "# Get Info Data From Records in Records HashMap\n",
    "def getInfoData (hashMap, key = \"TLOD\"):\n",
    "    data, excluded = [], {}\n",
    "    for md5, record in hashMap.items():\n",
    "        try:\n",
    "            data.append(record.INFO[key])\n",
    "        except:\n",
    "            excluded[md5] = record\n",
    "    return data, excluded\n",
    "\n",
    "# Get Format Data From Records in Records HashMap\n",
    "def getFormatData (hashMap, key = \"AF\", sampleIdx = 0):\n",
    "    data, excluded = [], {}\n",
    "    types = set()\n",
    "    for md5, record in hashMap.items():\n",
    "        try:\n",
    "            sample = record.samples[sampleIdx]\n",
    "            data.append(sample[key])\n",
    "        except:\n",
    "            excluded[md5] = record\n",
    "    return data, excluded\n",
    "\n",
    "# Retrieve Passing Variants (i.e. Those Which Have No Failing Filters)\n",
    "def passingVariants (hashMap):\n",
    "    passing = {}\n",
    "    for md5, record in hashMap.items():\n",
    "        if len(record.FILTER) == 0:\n",
    "            passing[md5] = record\n",
    "    return passing\n",
    "\n",
    "#\n",
    "# Statistics Computation\n",
    "#\n",
    "\n",
    "# Compute Quartiles of a Vector\n",
    "def quartiles(vector):\n",
    "    from statistics import median\n",
    "    sort = sorted(vector)\n",
    "    mid = len(sort) // 2\n",
    "    if (len(sort) % 2 == 0):\n",
    "        lowerQ = median(sort[:mid])\n",
    "        upperQ = median(sort[mid:])\n",
    "    else:\n",
    "        lowerQ = median(sort[:mid])\n",
    "        upperQ = median(sort[mid+1:])\n",
    "    return lowerQ, upperQ    \n",
    "\n",
    "# Generate Basic Statistics Summary\n",
    "def stats(vector, title = \"Title\"):\n",
    "    lowerQ, upperQ = quartiles(vector)\n",
    "    print(\"%s\\n\" % title)\n",
    "    print(\"Measures of Central Tendency\")\n",
    "    print(\"\\tMean          %s\"  % mean(vector))\n",
    "    print(\"\\tMedian        %s\"  % median(vector))\n",
    "    print(\"\\tMode          %s\"  % mode(vector))\n",
    "    print(\"Measures of Spread\")\n",
    "    print(\"\\tstdev         %s\"  % stdev(vector))\n",
    "    print(\"\\tvariance      %s\"  % variance(vector))\n",
    "    print(\"Distribution\")\n",
    "    print(\"\\tMin           %s\"  % min(vector))\n",
    "    print(\"\\tLower Quatile %s\"  % lowerQ)\n",
    "    print(\"\\tMedian        %s\"  % median(vector))\n",
    "    print(\"\\tUpper Quatile %s\"  % upperQ)\n",
    "    print(\"\\tMax           %s\\n\"% max(vector))\n",
    "    \n",
    "def printStatistics (analysis):\n",
    "    for threshold, records in analysis.items():\n",
    "        brk()\n",
    "        print(\"Tumor LOD Threshold: %d\\n\" % threshold)\n",
    "        print(\"\\tTrue Positive:     %d\" % len(records[\"tp\"]))\n",
    "        print(\"\\tTrue Negative:     %d\" % len(records[\"tn\"]))\n",
    "        print(\"\\tFalse Positive:    %d\" % len(records[\"fp\"]))\n",
    "        print(\"\\tFalse Negative:    %d\\n\" % len(records[\"fn\"]))\n",
    "        print(\"\\tTPR:               %0.2f%%\" % (records[\"tpr\"] * 100))\n",
    "        print(\"\\tTNR:               %0.2f%%\" % (records[\"tnr\"] * 100))\n",
    "        print(\"\\tFPR:               %0.2f%%\" % (records[\"fpr\"] * 100))\n",
    "        print(\"\\tFNR:               %0.2f%%\\n\" % (records[\"fnr\"] * 100))\n",
    "        print(\"\\tSensitivity:       %0.2f%%\" % (records[\"sensitivity\"] * 100))\n",
    "        print(\"\\tSpecificity:       %0.2f%%\\n\" % (records[\"specificity\"] * 100))\n",
    "        print(\"\\tPrecision:         %0.2f%%\" % (records[\"precision\"] * 100))\n",
    "        print(\"\\tRecall:            %0.2f%%\\n\" % (records[\"recall\"] * 100))\n",
    "        print(\"\\tAccuracy:          %0.2f%%\" % (records[\"accuracy\"] * 100))\n",
    "        print(\"\\tF1-Score:          %0.2f%%\" % (records[\"f1score\"] * 100))\n",
    "        print(\"\\tFDR:               %0.2f%%\\n\" % (records[\"fdr\"] * 100))\n",
    "        brk()\n",
    "\n",
    "# Print Best by Some Metric\n",
    "def printBest (analysis, metric = \"accuracy\"):\n",
    "    threshold, best = max(enumerate([records[metric] for threshold, records in analysis.items()]), key=itemgetter(1))\n",
    "    records = analysis[threshold]\n",
    "    print(\"Best Threshold by '%s'\\n\" % metric)\n",
    "    print(\"Tumor LOD Threshold: %d\\n\" % threshold)\n",
    "    print(\"\\tTrue Positive:     %d\" % len(records[\"tp\"]))\n",
    "    print(\"\\tTrue Negative:     %d\" % len(records[\"tn\"]))\n",
    "    print(\"\\tFalse Positive:    %d\" % len(records[\"fp\"]))\n",
    "    print(\"\\tFalse Negative:    %d\\n\" % len(records[\"fn\"]))\n",
    "    print(\"\\tTPR:               %0.2f%%\" % (records[\"tpr\"] * 100))\n",
    "    print(\"\\tTNR:               %0.2f%%\" % (records[\"tnr\"] * 100))\n",
    "    print(\"\\tFPR:               %0.2f%%\" % (records[\"fpr\"] * 100))\n",
    "    print(\"\\tFNR:               %0.2f%%\\n\" % (records[\"fnr\"] * 100))\n",
    "    print(\"\\tSensitivity:       %0.2f%%\" % (records[\"sensitivity\"] * 100))\n",
    "    print(\"\\tSpecificity:       %0.2f%%\\n\" % (records[\"specificity\"] * 100))\n",
    "    print(\"\\tPrecision:         %0.2f%%\" % (records[\"precision\"] * 100))\n",
    "    print(\"\\tRecall:            %0.2f%%\\n\" % (records[\"recall\"] * 100))\n",
    "    print(\"\\tAccuracy:          %0.2f%%\" % (records[\"accuracy\"] * 100))\n",
    "    print(\"\\tF1-Score:          %0.2f%%\\n\" % (records[\"f1score\"] * 100))\n",
    "    print(\"\\tFDR:               %0.2f%%\" % (records[\"fdr\"] * 100))\n",
    "    print(\"\\tFOR:               %0.2f%%\\n\" % (records[\"for\"] * 100))\n",
    "    print(\"\\tNPV:               %0.2f%%\" % (records[\"npv\"] * 100))\n",
    "    print(\"\\tPPV:               %0.2f%%\\n\" % (records[\"ppv\"] * 100))\n",
    "    print(\"\\tDiagnostic OR:     %0.2f\\n\" % (records[\"diagnosticOR\"] * 100))\n",
    "    \n",
    "#\n",
    "# Repeated Computations\n",
    "#\n",
    "\n",
    "def computeQuals (hashMap):\n",
    "    # Compute Quality Score Approximations\n",
    "    QS = getFormatData(hashMap, \"QSS\")[0]\n",
    "    AD = getFormatData(hashMap, \"AD\")[0]\n",
    "    # Compute Mean Quality Scores for Reference & Alternate Alleles\n",
    "    refQS = []\n",
    "    altQS = []\n",
    "    for qsPair, adPair in zip(QS, AD):\n",
    "        if adPair[0] == 0 or adPair[1] == 0:\n",
    "            pass\n",
    "        else:\n",
    "            refQS.append((qsPair[0] / adPair[0]))\n",
    "            altQS.append((qsPair[1] / adPair[1]))\n",
    "    return refQS, altQS\n",
    "\n",
    "# Split Vector by Index of Value Ranges - Default by Value\n",
    "def generateSplits (vector, n = 10, median = False):\n",
    "    if median:\n",
    "        # Split Vectors n Times by Their Median (Attempt to Evenly Distribute Vector by Rounding, Similar to a Split by Index)\n",
    "        splits    = [vector[round(i * (len(vector) / n)): round((i + 1) * (len(vector) / n))] for i in range(n)]\n",
    "        vecRanges = [(min(split), max(split)) for split in splits]\n",
    "    else:\n",
    "        # Sum Vector and Distribute Evenly by Value\n",
    "        vecMin, vecMax = min(vector), max(vector)\n",
    "        vecRanges = [(vecMin + (x * ((vecMax - vecMin) / n)), vecMin + ((x + 1) * ((vecMax - vecMin) / n))) for x in range(n)]\n",
    "        splits    = [[x for x in vector if (x >= vecRange[0] and x < vecRange[1])] for vecRange in vecRanges]\n",
    "    return splits, vecRanges\n",
    "\n",
    "def getRanges (splits):\n",
    "    ranges = []\n",
    "    for split in splits:\n",
    "        ranges.append([min(split), max(split)])\n",
    "    return ranges    \n",
    "\n",
    "#\n",
    "# Interface Management\n",
    "#\n",
    "\n",
    "# Print iterations progress\n",
    "def printProgress (iteration, total, prefix = '', suffix = '', decimals = 1, barLength = 100):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        barLength   - Optional  : character length of bar (Int)\n",
    "    \"\"\"\n",
    "    formatStr = \"{0:.\" + str(decimals) + \"f}\"\n",
    "    percent = formatStr.format(100 * (iteration / float(total)))\n",
    "    filledLength = int(round(barLength * iteration / float(total)))\n",
    "    bar = '█' * filledLength + '-' * (barLength - filledLength)\n",
    "    sys.stdout.write('\\r%s |%s| %s%s %s' % (prefix, bar, percent, '%', suffix)),\n",
    "    if iteration == total:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# Print a Break\n",
    "def brk(char = \"-\", n = 50):\n",
    "    print(\"\\n\" + (\"-\" * n) + \"\\n\")    \n",
    "\n",
    "#\n",
    "# Plotting\n",
    "#\n",
    "\n",
    "# Generate a Simple Inline Plot\n",
    "def simpleInlinePlot (x, y, title = \"\", xlabel = \"\", ylabel = \"\", color = \"green\", plotType = \"plot\", size = (12, 12), dpi = 1200, domain = [], range = [], opacity = 0.1, bins = 1000):\n",
    "    # Setup\n",
    "    figure = Plot.figure(1, size, dpi = dpi)\n",
    "    domain = domain if len(domain) == 2 else [min(x), max(x)]\n",
    "    range  = range if len(range) == 2 else [min(y), max(y)]\n",
    "    # Plot\n",
    "    Plot.subplot(1,1,1)\n",
    "    if plotType == \"hist\":\n",
    "        getattr(Plot, plotType)(y, bins = bins, color=color, lw=2, alpha = opacity)\n",
    "    if plotType == \"plot\":\n",
    "        Plot.xlim(domain)\n",
    "        Plot.ylim(range)\n",
    "        getattr(Plot, plotType)(x, y, color=color, lw=2, alpha = opacity)\n",
    "        Plot.plot([0, 1], [0, 95000], color='navy', lw=2, linestyle='--')\n",
    "    if plotType == \"scatter\":\n",
    "        Plot.xlim(domain)\n",
    "        Plot.ylim(range)\n",
    "        getattr(Plot, plotType)(x, y, color = color, alpha = opacity)\n",
    "    axis = figure.add_subplot(1,1,1)\n",
    "    axis.set_title(title, fontsize = 16)\n",
    "    axis.set_xlabel(xlabel, fontsize = 10)\n",
    "    axis.set_ylabel(ylabel, fontsize = 10)\n",
    "    if plotType == \"bar\":\n",
    "        assert len(x) == len(y)\n",
    "        xs = [int(n) for n in Np.arange(len(x))]\n",
    "        rects = axis.bar(xs, y, color = color, align = \"center\")\n",
    "        i = 0\n",
    "        for rect in rects:\n",
    "            h = rect.get_height()\n",
    "            label = x[i]\n",
    "            axis.text(rect.get_x() + (rect.get_width() / 2), 1.05 * h, label, ha = 'center', va = 'bottom')\n",
    "            i += 1\n",
    "    Plot.show()\n",
    "\n",
    "# Generate a Simple Histogram Plot\n",
    "def simpleHist (x, bins = 100, pdf = False, title = \"\", xlabel = \"\", ylabel = \"\", color = \"green\", opacity = 1.0, size = (12, 12), dpi = 1200):\n",
    "    norm = 1 if pdf else 0\n",
    "    # Setup\n",
    "    figure = Plot.figure(1, size, dpi = dpi)\n",
    "    # Plot\n",
    "    Plot.subplot(1,1,1)\n",
    "    Plot.hist(x, bins = bins, normed = norm, color = color, alpha = opacity)\n",
    "    # Axis Stuff\n",
    "    axis = figure.add_subplot(1,1,1)\n",
    "    axis.set_title(title, fontsize = 16)\n",
    "    axis.set_xlabel(xlabel, fontsize = 10)\n",
    "    axis.set_ylabel(ylabel, fontsize = 10)\n",
    "    Plot.show()\n",
    "    \n",
    "# Generates a Plot Scatter\n",
    "def scatterXY (analysis, x, y, color = \"green\", opacity = 0.5, n = 100, skip = 1, method = \"scatter\"):\n",
    "    X = [analysis[threshold][x] for threshold in range(0, n, skip)]\n",
    "    Y = [analysis[threshold][y] for threshold in range(0, n, skip)]\n",
    "    return getattr(Plot, method)(X, Y, color = color, alpha = opacity), X, Y\n",
    "    \n",
    "def plotCurve (conditions, labels, xKey = \"\", yKey = \"\", xLabel = \"\", yLabel = \"\", title = \"Title\", colors = [\"green\", \"orange\", \"red\", \"purple\", \"blue\"], diag = 0, method = \"plot\", legendLoc = \"lower right\"):\n",
    "    # Setup\n",
    "    fig         = Plot.figure(1, (12, 12), dpi = 1200)\n",
    "    axis        = fig.add_subplot(111)\n",
    "    axis.set_xlabel(xLabel, fontsize = 10)\n",
    "    axis.set_ylabel(yLabel, fontsize = 10)\n",
    "    # Scatter\n",
    "    legendKeys  = []\n",
    "    i           = 0\n",
    "    nLabels     = []\n",
    "    assert len(conditions) == len(labels)\n",
    "    # Plot Conditions\n",
    "    for condition in conditions:\n",
    "        colorIdx = i % len(colors)\n",
    "        scattered, X, Y = scatterXY(condition, xKey, yKey, colors[colorIdx], method = method)\n",
    "        auc = metrics.auc(X, Y)\n",
    "        legendKeys.append(scattered)\n",
    "        label = \"%s (AUC = %.4f)\" % (str(labels[i]), auc) \n",
    "        nLabels.append(label)\n",
    "        i += 1\n",
    "        \n",
    "    # Plot Diagonal\n",
    "    if diag is \"bottom\":\n",
    "        Plot.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "    if diag is \"top\":\n",
    "        Plot.plot([0, 1], [1, 0], color='navy', lw=1, linestyle='--')\n",
    "    Plot.ylim([0, 1])\n",
    "    Plot.xlim([0, 1])\n",
    "    Plot.title(title, fontsize = 16)\n",
    "    # Plot Legend\n",
    "    if method is \"scatter\":\n",
    "        Plot.legend(legendKeys, nLabels, loc = legendLoc, fontsize = 16)\n",
    "    else:\n",
    "        handles = [mpatches.Patch(color = key[0]._color, label = label) for key, label in zip(legendKeys, nLabels)]\n",
    "        Plot.legend(handles=handles, loc = legendLoc, fontsize = 16)\n",
    "    # Render\n",
    "    Plot.show()\n",
    "    \n",
    "# Plot Maximum of Two Combined Values (e.g. Maximize TPR & TNR)\n",
    "def plotMaximized (analysis, x, y, color = \"red\", n = 100, skip = 1):\n",
    "    combinations = [analysis[threshold][x] + analysis[threshold][y] for threshold in range(0, n, skip)]\n",
    "    index, combination = max(enumerate(combinations), key=itemgetter(1))\n",
    "    return Plot.scatter(analysis[index][x], analysis[index][y], s=200, facecolors = 'none', edgecolors = color)\n",
    "\n",
    "# Quick & Dirty Function to Plot Multiple Curves & Stop me Polluting the Global Scope. Tsk Tsk. \n",
    "def plotCurves (c1Tups, c2Tups, truthSet, c1Map, c2Map, subsetKey = \"\", c1Label = \"\", c2Label = \"\", titleStr = \"\"):\n",
    "    i = 1\n",
    "    for c1, c2 in zip(c1Tups, c2Tups):\n",
    "        # Subset Hashmaps\n",
    "        c1Hm, excluded = subsetHashMapByFormatRange(c1Map, c1, key = subsetKey)\n",
    "        c2Hm, excluded = subsetHashMapByFormatRange(c2Map, c2, key = subsetKey)\n",
    "        # Regenerate Analysis on Subset\n",
    "        c1A = generateAnalyses(c1Hm, truthSet, \"TLOD\")\n",
    "        c2A = generateAnalyses(c2Hm, truthSet, \"TLOD\")\n",
    "        c1Title = c1Label + \" Range (%.2f, %.2f)\" % tuple(c1)\n",
    "        c2Title = c2Label + \" Range (%.2f, %.2f)\" % tuple(c2)\n",
    "        c1Legend = str(c1Label) + \", n = %d\" % len(c1Hm.keys())\n",
    "        c2Legend = str(c2Label) + \", n = %d\" % len(c2Hm.keys())\n",
    "        title = titleStr + \" (\" + str(i) + \")\\n\" +  c1Title + \" / \" + c2Title\n",
    "        # Call CurvePlotting Function\n",
    "        plotCurve([c1A, c2A], (c1Legend, c2Legend), xKey = \"specificity\", yKey = \"sensitivity\", xLabel = \"Specificity\", yLabel = \"Sensitivity\", title = title, diag = \"top\", method = \"plot\", legendLoc = \"lower left\")\n",
    "        i += 1\n",
    "        \n",
    "# Plot Multiple Curves on One Canvas\n",
    "def multiCurve (c1Tups, c2Tups, truthSet, c1Map, c2Map, subsetKey = \"\", c1Label = \"\", c2Label = \"\", titleStr = \"\", xKey = \"sensitivity\", yKey = \"specificity\", xLabel = \"Sensitivity\", yLabel = \"Specificity\", title = \"\", colors = [[\"#004400\", \"#005300\", \"#006200\", \"#007100\", \"#008000\", \"#008F00\", \"#009E00\", \"#00AD00\", \"#00BC00\", \"#00CC00\"], [\"#601D00\", \"#712300\", \"#822A00\", \"#933100\", \"#A43800\", \"#B53E00\", \"#C64500\", \"#D74C00\", \"#E85300\", \"#FA5A00\"]], diag = \"top\", method = \"plot\", legendLoc = \"lower left\"):\n",
    "    # Compute Curves\n",
    "    analyses = []\n",
    "    for c1, c2 in zip(c1Tups, c2Tups):\n",
    "        # Subset Hashmaps\n",
    "        c1Hm, excluded = subsetHashMapByFormatRange(c1Map, c1, key = subsetKey)\n",
    "        c2Hm, excluded = subsetHashMapByFormatRange(c2Map, c2, key = subsetKey)\n",
    "        # Regenerate Analysis on Subset\n",
    "        c1Analysis = generateAnalyses(c1Hm, truthSet, \"TLOD\")\n",
    "        c2Analysis = generateAnalyses(c2Hm, truthSet, \"TLOD\")\n",
    "        analyses.append([c1Analysis, c2Analysis])\n",
    "    # Plot Setup\n",
    "    fig         = Plot.figure(1, (12, 12), dpi = 1200)\n",
    "    axis        = fig.add_subplot(111)\n",
    "    axis.set_xlabel(xLabel, fontsize = 10)\n",
    "    axis.set_ylabel(yLabel, fontsize = 10)\n",
    "    alphaSteps = len(analyses) + 1\n",
    "    i = 0\n",
    "    # For Each Analysis\n",
    "    for analysis in analyses:\n",
    "        legendKeys = []\n",
    "        j = 0\n",
    "        alpha = ((i + 1) / alphaSteps * 0.8)\n",
    "        # For Each Condition\n",
    "        for condition in analysis:\n",
    "            colorIdx = i % len(colors[j])\n",
    "            # Call Scatter Function, \n",
    "            legendKeys.append(scatterXY(condition, xKey, yKey, colors[j][colorIdx], opacity = alpha, method = method))\n",
    "            j += 1\n",
    "        i += 1\n",
    "    # Plot\n",
    "    if diag is \"bottom\":\n",
    "        Plot.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "    if diag is \"top\":\n",
    "        Plot.plot([0, 1], [1, 0], color='navy', lw=1, linestyle='--')\n",
    "    Plot.ylim([0, 1])\n",
    "    Plot.xlim([0, 1])\n",
    "    Plot.title(title, fontsize = 16)\n",
    "    if method is \"scatter\":\n",
    "        Plot.legend(legendKeys, labels, loc = legendLoc, fontsize = 16)\n",
    "    else:\n",
    "        labels = [c1Label, c2Label]\n",
    "        handles = [mpatches.Patch(color = key[0]._color, label = label) for key, label in zip(legendKeys, labels)]\n",
    "        Plot.legend(handles=handles, loc = legendLoc, fontsize = 16)\n",
    "    Plot.show()\n",
    "    \n",
    "def plotQualityScores (ref, alt, title = \"Title\"):\n",
    "    # Setup\n",
    "    fig         = Plot.figure(1, (16, 12), dpi = 1200)\n",
    "    axis        = fig.add_subplot(111)\n",
    "    axis.set_ylabel('Quality Score', fontsize = 10)\n",
    "    axis.set_xlabel('Variant Allele', fontsize = 10)\n",
    "    # Scatter\n",
    "    r = Plot.scatter(range(len(ref)), ref, color = \"orange\", alpha = 0.2)\n",
    "    a = Plot.scatter(range(len(alt)), alt, color = \"blue\", alpha = 0.2)\n",
    "    # Plot\n",
    "    Plot.ylim([0, 40])\n",
    "    Plot.xlim([0, len(ref)])\n",
    "    Plot.title(title, fontsize = 16)\n",
    "    Plot.legend((r, a), ('Reference', 'Alternate'), loc = 'lower right', fontsize = 16)\n",
    "    Plot.show()\n",
    "    \n",
    "# Plot Mutect Filters by Frequency\n",
    "def plotFilterFrequencies (hashmap, title = \"\", xlabel = \"\", ylabel = \"\"):\n",
    "    from collections import defaultdict\n",
    "    # Which Filters are Catching Variants?\n",
    "    counts = defaultdict(int)\n",
    "    for md5hash, record in hashmap.items():\n",
    "        if len(record.FILTER) > 0:\n",
    "            for mutectFilter in record.FILTER:\n",
    "                counts[mutectFilter] += 1\n",
    "    # Get Frequencies\n",
    "    frequencies = {key : (value / len(hashmap)) for key, value in counts.items()}\n",
    "    # Plot Bar Plot\n",
    "    simpleInlinePlot(list(frequencies.keys()), list(frequencies.values()), title = title, xlabel = xlabel, ylabel = ylabel, plotType = \"bar\")\n",
    "    \n",
    "def plotMetrics(analysis, metrics = [\"sensitivity\", \"specificity\"], reduce = lambda x: len(x), title = \"Title\", colors = [\"red\", \"green\", \"yellow\", \"orange\"]):\n",
    "    metricsDict = { metric : [] for metric in metrics }\n",
    "    thresholds  = []\n",
    "    for threshold, records in analysis.items():\n",
    "        thresholds.append(threshold)\n",
    "        for metric in metrics:\n",
    "            if hasattr(records[metric], '__iter__'): \n",
    "                metricsDict[metric].append(len(records[metric]))\n",
    "            else:\n",
    "                metricsDict[metric].append(records[metric])\n",
    "    index = 0\n",
    "    figure = Plot.figure(1, (12, 12), dpi = 1200) \n",
    "    axis = figure.add_subplot(1,1,1)\n",
    "    axis.set_title(title, fontsize = 16)\n",
    "    axis.set_xlabel(\"Threshold\", fontsize = 10)\n",
    "    axis.set_ylabel(\"Performance\", fontsize = 10)\n",
    "    box = axis.get_position()\n",
    "    axis.set_position([box.x0, box.y0, box.width, box.height * 0.9])\n",
    "    for metric, values in metricsDict.items():\n",
    "        color = colors[index % len(colors)]\n",
    "        label = metric\n",
    "        x = thresholds\n",
    "        y = values\n",
    "        Plot.subplot(1,1,1)\n",
    "        Plot.plot(x, y, label = label, color = color, alpha = 0.6, lw = 2)\n",
    "        Plot.legend(fontsize = 16, loc = \"upper center\", ncol = 5, bbox_to_anchor=(0.5, -0.05))\n",
    "        index += 1\n",
    "    Plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash Variants For Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Init VCF Readers\n",
    "c1Reader       = VCF.Reader(open(condition1VCF, 'r'))\n",
    "c2Reader       = VCF.Reader(open(condition2VCF, 'r'))\n",
    "trReader       = VCF.Reader(open(truthVCF, 'r'))\n",
    "\n",
    "# Variant Record Properties to Define Uniqueness\n",
    "uniqueProps    = [\"CHROM\", \"POS\", \"REF\", \"ALT\"]\n",
    "\n",
    "#\n",
    "# Store Metadata References\n",
    "#\n",
    "\n",
    "# INFO Terms\n",
    "c1Infos        = c1Reader.infos\n",
    "c2Infos        = c2Reader.infos\n",
    "trInfos        = trReader.infos\n",
    "# Metadata\n",
    "c1Metadata     = c1Reader.metadata\n",
    "c2Metadata     = c2Reader.metadata\n",
    "trMetadata     = trReader.metadata\n",
    "\n",
    "# Filters\n",
    "c1Filters      = c1Reader.filters\n",
    "c2Filters      = c2Reader.filters\n",
    "trFilters      = trReader.filters\n",
    "\n",
    "# Formats\n",
    "c1Formats      = c1Reader.formats\n",
    "c2Formats      = c2Reader.formats\n",
    "trFormats      = trReader.formats\n",
    "\n",
    "#\n",
    "# Hash Variants\n",
    "#\n",
    "\n",
    "# Hash VCF Records for Comparison - Use Values of Unique Props to Generate Hash\n",
    "c1HashMap, c1Fail = hashVariants(c1Reader, uniqueProps, algorithm = \"sha512\")\n",
    "c2HashMap, c2Fail = hashVariants(c2Reader, uniqueProps, algorithm = \"sha512\")\n",
    "trHashMap, trFail = hashVariants(trReader, uniqueProps, algorithm = \"sha512\")\n",
    "\n",
    "# Sanity Check for Hash Collisions\n",
    "if c1Fail == c2Fail == trFail == False: \n",
    "    print(\"Status: No Hash Collisions Between VCF Records\")\n",
    "    \n",
    "# Retrieve Passing Variants\n",
    "c1Passing = passingVariants(c1HashMap)\n",
    "c2Passing = passingVariants(c2HashMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Analysis Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Sets      \n",
    "trSet   = set(trHashMap.keys())\n",
    "c1Set   = set(c1HashMap.keys())\n",
    "c2Set   = set(c2HashMap.keys())\n",
    "\n",
    "# Lengths\n",
    "tr      = len(trSet)\n",
    "c1      = len(c1Set)\n",
    "c2      = len(c2Set)\n",
    "\n",
    "# Generate Analyses - With Tumor LOD As Metric to Compute Statistics On\n",
    "condition1Analysis = generateAnalyses(c1HashMap, trSet, \"TLOD\")\n",
    "condition2Analysis = generateAnalyses(c2HashMap, trSet, \"TLOD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curve Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotCurve([condition1Analysis, condition2Analysis], [\"No BQSR\", \"BQSR\"], xKey = \"fpr\", yKey = \"tpr\", xLabel = \"False Positive Rate\", yLabel = \"True Positive Rate\", title = \"ROC Curve – Tumor LOD Thresholds (No BQSR v. BQSR)\", diag = \"bottom\", method = \"plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity Specificity Curve (No BQSR Condition v. BQSR Condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Generate Sensitivity-Specificity Curve\n",
    "#\n",
    "\n",
    "# Individual Plots\n",
    "plotCurves([(0.0, 1.0)], [(0.0, 1.0)], trSet, c1HashMap, c2HashMap, subsetKey = \"AF\", c1Label = \"No BQSR\", c2Label = \"BQSR\", titleStr = \"Sensitivity Specificity Curve – Tumor LOD Thresholds (No BQSR v. BQSR)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Look: What Threshold Results in The Max Combined Sensitivity-Specificity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Generate Sensitivity-Specificity Curve - With Maximum Combination\n",
    "#\n",
    "\n",
    "# Setup\n",
    "fig         = Plot.figure(1, (12, 12), dpi = 1200)\n",
    "axis        = fig.add_subplot(111)\n",
    "axis.set_ylabel('Sensitivity', fontsize = 10)\n",
    "axis.set_xlabel('Specificity', fontsize = 10)\n",
    "# Scatter\n",
    "c1, c1X, c1Y = scatterXY(condition1Analysis, \"specificity\", \"sensitivity\", \"green\")\n",
    "c2, c2X, c2Y = scatterXY(condition2Analysis, \"specificity\", \"sensitivity\", \"orange\")\n",
    "c1Auc = metrics.auc(c1X, c1Y)\n",
    "c2Auc = metrics.auc(c2X, c2Y)\n",
    "c1Label = \"No BQSR (AUC = %.4f)\" % c1Auc\n",
    "c2Label = \"BQSR (AUC = %.4f)\" % c2Auc\n",
    "# Annotate Maximized Threshold\n",
    "m  = plotMaximized(condition1Analysis, \"specificity\", \"sensitivity\")\n",
    "# Plot\n",
    "Plot.plot([1, 0], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "Plot.ylim([0, 1])\n",
    "Plot.xlim([0, 1])\n",
    "Plot.title(\"Sensitivity Specificity Curve – Tumor LOD Thresholds (No BQSR v. BQSR)\", fontsize = 16)\n",
    "Plot.legend((c1, c2), (c1Label, c2Label), loc = 'lower left', fontsize = 16)\n",
    "Plot.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Threshold Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No BQSR Condition Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "printBest(condition1Analysis) # Accuracy\n",
    "printBest(condition1Analysis, \"f1score\")\n",
    "printBest(condition1Analysis, \"ppv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BQSR Condition Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "printBest(condition2Analysis) # Accuracy\n",
    "printBest(condition2Analysis, \"f1score\")\n",
    "printBest(condition1Analysis, \"ppv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BQSR / No BQSR Low VAF Performance Comparison - All Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Metrics\n",
    "c1AfVals = sorted(getFormatData(c1HashMap, key=\"AF\")[0])\n",
    "c2AfVals = sorted(getFormatData(c2HashMap, key=\"AF\")[0])\n",
    "\n",
    "#\n",
    "# Low VAF\n",
    "#\n",
    "\n",
    "c1AfLowSplit = [x for x in c1AfVals if x > 0.0 and x <= 0.05]\n",
    "c2AfLowSplit = [x for x in c2AfVals if x > 0.0 and x <= 0.05]\n",
    "c1AfMedSplit = [x for x in c1AfVals if x > 0.05 and x <= 0.1]\n",
    "c2AfMedSplit = [x for x in c2AfVals if x > 0.05 and x <= 0.1]\n",
    "c1AfHighSplit = [x for x in c1AfVals if x > 0.1 and x <= 0.15]\n",
    "c2AfHighSplit = [x for x in c2AfVals if x > 0.1 and x <= 0.15]\n",
    "\n",
    "# Low Range Tuples\n",
    "c1AfLowTups = (min(c1AfLowSplit), max(c1AfLowSplit))\n",
    "c2AfLowTups = (min(c2AfLowSplit), max(c2AfLowSplit))\n",
    "c1AfMedTups = (min(c1AfMedSplit), max(c1AfMedSplit))\n",
    "c2AfMedTups = (min(c2AfMedSplit), max(c2AfMedSplit))\n",
    "c1AfHighTups = (min(c1AfHighSplit), max(c1AfHighSplit))\n",
    "c2AfHighTups = (min(c2AfHighSplit), max(c2AfHighSplit))\n",
    "\n",
    "# Note: We could just hand the range tuples - but this bounds the tuple values by the actual data values present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 - 0.05 VAF - All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Individual Plots\n",
    "plotCurves([c1AfLowTups], [c2AfLowTups], trSet, c1HashMap, c2HashMap, subsetKey = \"AF\", c1Label = \"No BQSR\", c2Label = \"BQSR\", titleStr = \"Sensitivity-Specificity by All Variant Allele Frequency Interval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.05 - 0.1 VAF - All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Individual Plots\n",
    "plotCurves([c1AfMedTups], [c2AfMedTups], trSet, c1HashMap, c2HashMap, subsetKey = \"AF\", c1Label = \"No BQSR\", c2Label = \"BQSR\", titleStr = \"Sensitivity-Specificity by All Variant Allele Frequency Interval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 - 0.15 VAF - All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Individual Plots\n",
    "plotCurves([c1AfHighTups], [c2AfHighTups], trSet, c1HashMap, c2HashMap, subsetKey = \"AF\", c1Label = \"No BQSR\", c2Label = \"BQSR\", titleStr = \"Sensitivity-Specificity by All Variant Allele Frequency Interval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BQSR / No BQSR Low VAF Performance Comparison - Passing Variants\n",
    "### Is MuTect (Under Default Settings) Generating False Negatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Metrics\n",
    "c1AfVals, excl = getFormatData(c1Passing, key=\"AF\")\n",
    "c2AfVals, excl = getFormatData(c2Passing, key=\"AF\")\n",
    "\n",
    "c1AfVals = sorted(c1AfVals)\n",
    "c2AfVals = sorted(c2AfVals)\n",
    "\n",
    "#\n",
    "# Low VAF\n",
    "# \n",
    "\n",
    "c1AfLowSplit = [x for x in c1AfVals if x > 0.0 and x <= 0.05]\n",
    "c2AfLowSplit = [x for x in c2AfVals if x > 0.0 and x <= 0.05]\n",
    "c1AfMedSplit = [x for x in c1AfVals if x > 0.05 and x <= 0.1]\n",
    "c2AfMedSplit = [x for x in c2AfVals if x > 0.05 and x <= 0.1]\n",
    "c1AfHighSplit = [x for x in c1AfVals if x > 0.1 and x <= 0.15]\n",
    "c2AfHighSplit = [x for x in c2AfVals if x > 0.1 and x <= 0.15]\n",
    "\n",
    "# Low Range Tuples\n",
    "c1AfLowTups = (min(c1AfLowSplit), max(c1AfLowSplit))\n",
    "c2AfLowTups = (min(c2AfLowSplit), max(c2AfLowSplit))\n",
    "c1AfMedTups = (min(c1AfMedSplit), max(c1AfMedSplit))\n",
    "c2AfMedTups = (min(c2AfMedSplit), max(c2AfMedSplit))\n",
    "c1AfHighTups = (min(c1AfHighSplit), max(c1AfHighSplit))\n",
    "c2AfHighTups = (min(c2AfHighSplit), max(c2AfHighSplit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 - 0.05 VAF - Passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Individual Plots\n",
    "plotCurves([c1AfLowTups], [c2AfLowTups], trSet, c1Passing, c2Passing, subsetKey = \"AF\", c1Label = \"No BQSR\", c2Label = \"BQSR\", titleStr = \"Sensitivity-Specificity by Passing Variant Allele Frequency Interval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.05 - 0.1 VAF - Passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Individual Plots\n",
    "plotCurves([c1AfMedTups], [c2AfMedTups], trSet, c1Passing, c2Passing, subsetKey = \"AF\", c1Label = \"No BQSR\", c2Label = \"BQSR\", titleStr = \"Sensitivity-Specificity by Passing Variant Allele Frequency Interval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 - 0.15 VAF - Passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Individual Plots\n",
    "plotCurves([c1AfHighTups], [c2AfHighTups], trSet, c1Passing, c2Passing, subsetKey = \"AF\", c1Label = \"No BQSR\", c2Label = \"BQSR\", titleStr = \"Sensitivity-Specificity by Passing Variant Allele Frequency Interval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which Mutect2 Filters Are Creating False Negatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "#\n",
    "# Truth Set\n",
    "#\n",
    "\n",
    "# Subset HashMaps by VAF Range\n",
    "trSub, excluded = subsetHashMapByInfoThreshold(trHashMap, 0.15, operation = \"<=\", key = \"VAF\")\n",
    "# Truth Set 0.10 - 0.15\n",
    "trSubGt10, trExcludedLt10 = subsetHashMapByInfoThreshold(trSub, 0.10, operation = \"<=\", key = \"VAF\")\n",
    "# Truth Set 0.00 - 0.05; 0.05 - 0.10\n",
    "trSubGt00, trSubGt05 = subsetHashMapByInfoThreshold(trExcludedLt10, 0.05, operation = \"<=\", key = \"VAF\")\n",
    "\n",
    "#\n",
    "# No BQSR - All\n",
    "#\n",
    "\n",
    "c1Sub, excluded = subsetHashMapByFormatThreshold(c1HashMap, 0.15, operation = \"<=\", key = \"AF\")\n",
    "# All - No BQSR Set 0.10 - 0.15\n",
    "c1SubGt10, c1ExcludedLt10 = subsetHashMapByFormatThreshold(c1Sub, 0.10, operation = \"<=\", key = \"AF\")\n",
    "# All - No BQSR Set 0.00 - 0.05; 0.05 - 0.10\n",
    "c1SubGt00, c1SubGt05 = subsetHashMapByFormatThreshold(c1ExcludedLt10, 0.05, operation = \"<=\", key = \"AF\")\n",
    "\n",
    "#\n",
    "# No BQSR - Passing\n",
    "#\n",
    "\n",
    "c1PassSub, excluded = subsetHashMapByFormatThreshold(c1Passing, 0.15, operation = \"<=\", key = \"AF\")\n",
    "# Passing - No BQSR Set 0.10 - 0.15\n",
    "c1PassSubGt10, c1PassExcludedLt10 = subsetHashMapByFormatThreshold(c1PassSub, 0.10, operation = \"<=\", key = \"AF\")\n",
    "# Passing - No BQSR Set 0.00 - 0.05; 0.05 - 0.10\n",
    "c1PassSubGt00, c1PassSubGt05 = subsetHashMapByFormatThreshold(c1PassExcludedLt10, 0.05, operation = \"<=\", key = \"AF\")\n",
    "\n",
    "#\n",
    "# BQSR - All\n",
    "#\n",
    "\n",
    "c2Sub, excluded = subsetHashMapByFormatThreshold(c2HashMap, 0.15, operation = \"<=\", key = \"AF\")\n",
    "# All - BQSR Set 0.10 - 0.15\n",
    "c2SubGt10, c2ExcludedLt10 = subsetHashMapByFormatThreshold(c2Sub, 0.10, operation = \"<=\", key = \"AF\")\n",
    "# All - BQSR Set 0.00 - 0.05; 0.05 - 0.10\n",
    "c2SubGt00, c2SubGt05 = subsetHashMapByFormatThreshold(c2ExcludedLt10, 0.05, operation = \"<=\", key = \"AF\")\n",
    "\n",
    "#\n",
    "# BQSR - Passing\n",
    "#\n",
    "\n",
    "c2PassSub, excluded = subsetHashMapByFormatThreshold(c2Passing, 0.15, operation = \"<=\", key = \"AF\")\n",
    "# Passing - BQSR Set 0.10 - 0.15\n",
    "c2PassSubGt10, c2PassExcludedLt10 = subsetHashMapByFormatThreshold(c2PassSub, 0.10, operation = \"<=\", key = \"AF\")\n",
    "# Passing - BQSR Set 0.00 - 0.05; 0.05 - 0.10\n",
    "c2PassSubGt00, c2PassSubGt05 = subsetHashMapByFormatThreshold(c2PassExcludedLt10, 0.05, operation = \"<=\", key = \"AF\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Filter Frequencies for False Negatives - VAF [0.10 - 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot Filter Frequencies – False Negatives - No BQSR Set 0.10 - 0.15\n",
    "\n",
    "# Get True Keys For False Negatives\n",
    "diff = set(c1SubGt10.keys()) - set(c1PassSubGt10.keys())\n",
    "c1SubGt10Fn = subsetHashMapByKeys(c1SubGt10, diff)\n",
    "if len(c1SubGt10Fn) > 0:\n",
    "    # Generate Filter Frequencies Plot\n",
    "    plotFilterFrequencies(c1SubGt10Fn, title = \"Filter Frequencies for False Negatives (No BQSR) - VAF [0.10 - 0.15]\", xlabel = \"Filters\", ylabel = \"Proportion\")\n",
    "\n",
    "# Plot Filter Frequencies – False Negatives - BQSR Set 0.10 - 0.15\n",
    "\n",
    "# Get True Keys For False Negatives\n",
    "diff = set(c2SubGt10.keys()) - set(c2PassSubGt10.keys())\n",
    "c2SubGt10Fn = subsetHashMapByKeys(c2SubGt10, diff)\n",
    "if len(c2SubGt10Fn) > 0:\n",
    "    # Generate Filter Frequencies Plot\n",
    "    plotFilterFrequencies(c2SubGt10Fn, title = \"Filter Frequencies for False Negatives (BQSR) - VAF [0.10 - 0.15]\", xlabel = \"Filters\", ylabel = \"Proportion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Filter Frequencies for False Negatives - VAF [0.05 - 0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot Filter Frequencies – False Negatives - No BQSR Set 0.05 - 0.10\n",
    "\n",
    "# Get True Keys For False Negatives\n",
    "diff = set(c1SubGt05.keys()) - set(c1PassSubGt05.keys())\n",
    "c1SubGt05Fn = subsetHashMapByKeys(c1SubGt05, diff)\n",
    "if len(c1SubGt05Fn) > 0:\n",
    "    # Generate Filter Frequencies Plot\n",
    "    plotFilterFrequencies(c1SubGt05Fn, title = \"Filter Frequencies for False Negatives (No BQSR) - VAF [0.05 - 0.10]\", xlabel = \"Filters\", ylabel = \"Proportion\")\n",
    "\n",
    "# Plot Filter Frequencies – False Negatives - BQSR Set 0.05 - 0.10\n",
    "\n",
    "# Get True Keys For False Negatives\n",
    "diff = set(c2SubGt05.keys()) - set(c2PassSubGt05.keys())\n",
    "c2SubGt05Fn = subsetHashMapByKeys(c2SubGt05, diff)\n",
    "if len(c2SubGt05Fn) > 0:\n",
    "    # Generate Filter Frequencies Plot\n",
    "    plotFilterFrequencies(c2SubGt05Fn, title = \"Filter Frequencies for False Negatives (BQSR) - VAF [0.05 - 0.10]\", xlabel = \"Filters\", ylabel = \"Proportion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Filter Frequencies for False Negatives - VAF [< 0.01 - 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot Filter Frequencies – False Negatives - No BQSR Set < 0.01 - 0.05\n",
    "\n",
    "# Get True Keys For False Negatives\n",
    "diff = set(c1SubGt00.keys()) - set(c1PassSubGt00.keys())\n",
    "c1SubGt00Fn = subsetHashMapByKeys(c1SubGt00, diff)\n",
    "if len(c1SubGt00Fn) > 0:\n",
    "    # Generate Filter Frequencies Plot\n",
    "    plotFilterFrequencies(c1SubGt00Fn)\n",
    "\n",
    "# Plot Filter Frequencies – False Negatives - BQSR Set < 0.01 - 0.05\n",
    "\n",
    "# Get True Keys For False Negatives\n",
    "diff = set(c2SubGt00.keys()) - set(c2PassSubGt00.keys())\n",
    "c2SubGt00Fn = subsetHashMapByKeys(c2SubGt00, diff)\n",
    "if len(c2SubGt00Fn) > 0:\n",
    "    # Generate Filter Frequencies Plot\n",
    "    plotFilterFrequencies(c2SubGt00Fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutect2 Performance at Low VAF\n",
    "## Called / Not Called by MuTect2 by VAF Range [> 0.00 - 0.05]; [0.05 - 0.10]; [0.10 - 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Map Analysis\n",
    "#\n",
    "\n",
    "trCombinations = [trSubGt10, trSubGt05, trSubGt00]\n",
    "combinations = [\n",
    "    [\n",
    "        {\"label\": \"No BQSR - All - [0.10 - 0.15] VAF\", \"data\": c1SubGt10}, \n",
    "        {\"label\": \"No BQSR - All - [0.05 - 0.10] VAF\", \"data\": c1SubGt05},\n",
    "        {\"label\": \"No BQSR - All - [> 0.00 - 0.05] VAF\", \"data\": c1SubGt00}\n",
    "    ],\n",
    "    [\n",
    "        {\"label\": \"BQSR - All - [0.10 - 0.15] VAF\", \"data\": c2SubGt10}, \n",
    "        {\"label\": \"BQSR - All - [0.05 - 0.10] VAF\", \"data\": c2SubGt05}, \n",
    "        {\"label\": \"BQSR - All - [> 0.00 - 0.05] VAF\", \"data\": c2SubGt00}\n",
    "    ],\n",
    "    [\n",
    "        {\"label\": \"No BQSR - Passing - [0.10 - 0.15] VAF\", \"data\": c1PassSubGt10}, \n",
    "        {\"label\": \"No BQSR - Passing - [0.05 - 0.10] VAF\", \"data\": c1PassSubGt05}, \n",
    "        {\"label\": \"No BQSR - Passing - [> 0.00 - 0.05] VAF\", \"data\": c1PassSubGt00}\n",
    "    ],\n",
    "    [\n",
    "        {\"label\": \"BQSR - Passing - [0.10 - 0.15] VAF\", \"data\": c2PassSubGt10}, \n",
    "        {\"label\": \"BQSR - Passing - [0.05 - 0.10] VAF\", \"data\": c2PassSubGt05}, \n",
    "        {\"label\": \"BQSR - Passing - [> 0.00 - 0.05] VAF\", \"data\": c2PassSubGt00}\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Generate Analyses\n",
    "analysisSets = []\n",
    "for combination in combinations:\n",
    "    for truth, condition in zip(trCombinations, combination):\n",
    "        a = generateAnalysis(condition[\"data\"], truth)\n",
    "        analysisSets.append({\"label\": condition[\"label\"], \"analysis\": a})\n",
    "\n",
    "# Print Analyses\n",
    "i = 0\n",
    "for analysisSet in analysisSets:\n",
    "    print(\"Mutect2 Performance: %s\" % analysisSet[\"label\"])\n",
    "    print(\"\\tCalled by MuTect2 (TPR): %.4f%%\" % analysisSet[\"analysis\"][\"tpr\"])\n",
    "    print(\"\\tMissed by MuTect2 (FNR): %.4f%%\" % analysisSet[\"analysis\"][\"fnr\"])\n",
    "    print(\"\\tTNR:                     %.4f%%\" % analysisSet[\"analysis\"][\"tnr\"])\n",
    "    print(\"\\tFPR:                     %.4f%%\" % analysisSet[\"analysis\"][\"fpr\"])\n",
    "    print(\"\\tSensitivity:             %.4f%%\" % analysisSet[\"analysis\"][\"sensitivity\"])\n",
    "    print(\"\\tSpecificity:             %.4f%%\" % analysisSet[\"analysis\"][\"specificity\"])\n",
    "    print(\"\\tAccuracy:                %.4f%%\" % analysisSet[\"analysis\"][\"accuracy\"])\n",
    "    print(\"n = %d\" % analysisSet[\"analysis\"][\"n\"])\n",
    "    brk()\n",
    "    i += 1\n",
    "    if (i % 3 == 0):\n",
    "        print(\"==================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
